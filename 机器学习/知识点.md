## 选择

C4.5选择属性用的是**信息增益率**

决策树**错误**的说法：决策树的深度越大越好

在决策树算法中，**特征选择**是用来选择最佳分裂特征的

岭回归使用L2正则化，Lasso回归使用L1正则化

在回归问题中，如果模型的预测值与实际值差异很小，但模型复杂度很高，这是过拟合

AdaBoost算法通过**根据前一个模型的预测错误率来调整训练样本的权重**

决策树**错误**的说法：受生物进化启发

分析营销投入和销售收入的关系可以使用**回归分析**

在线性回归中，如果数据的真实性是非线性的，但模型假设为线性，这通常会导致**欠拟合**

Boosting	强依赖	串行

Bagging  弱依赖  并行  随机森林为代表

## 判断

**全是对的**

监督学习需要有标记的数据集进行训练

过拟合是指模型在训练数据上表现良好，但在未见过的数据上表现不佳

在多元线性回归中，每个输入特征都有一个对应的系数，这些系数表示了特征对目标变量的权重

创建决策树的基本原则就是简单的就是最好的，只要能实现同意的功能，决策树越简单越好

信息增益总是大于或等于0

在AdaBoost算法中，被前一个学习器错误分类的样本会被赋予更高的权重

---

## 多选

决策树算法中的停止条件可能包括 ( )。

A. 所有样本都属于同一类

B. 没有更多特征可分裂

C. 达到预设的树深度

D. 所有节点的熵都为零

答案：ABCD

</br>

下列关于随机森林的描述正确的是 ( )。

A. 样本抽取方式与 Bagging 一致

B. 每次从所有属性中随机抽取t个属性来训练分类器

C. 每次从所有样本中选取一定比例的样本来训练分类器

D. 可以使用不同的决策树的组合来构建分类模型

答案：ABCD

</br>

对 AdaBoost 描述正确的是 ( )。

A. 可以集成出训练误差任意低的分类器

B. 基础分类器可以任意弱

C. 采用串行训练模式

D. 被当前基础分类器分错的样本的权重将会减小

答案：ABC

</br>

决策树的说法正确的是 ( )。

A. 它易于理解，可解释性强

B. 其可作为分类算法，也可用于回归模型

C. CART 使用的是二叉树

D. 不能处理连续型特征

答案：ABC

</br>

关于集成学习的说法正确的有 ( )。

A. 团结力量大

B. 三个臭皮匠顶个诸葛亮

C. 好而不同

答案：ABC

## 论述

讲解分类和回归有哪些算法，并举例出2到3个应用场景



